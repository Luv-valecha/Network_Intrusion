{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9065c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the project root (assuming you run the notebook from /your_project/notebooks/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Now, import your module\n",
    "from API.model.ANN import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04875513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>239</td>\n",
       "      <td>16225</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>325</td>\n",
       "      <td>3983</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>285</td>\n",
       "      <td>263</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   service  flag  src_bytes  dst_bytes  same_srv_rate  diff_srv_rate  \\\n",
       "0       22     9        239      16225           1.00           0.00   \n",
       "1       39     5          0          0           0.10           0.05   \n",
       "2       17     5          0          0           0.25           0.17   \n",
       "3       22     9        325       3983           1.00           0.00   \n",
       "4       22     9        285        263           1.00           0.00   \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                 255                    1.00                    0.00   \n",
       "1                  22                    0.09                    0.06   \n",
       "2                  64                    0.25                    0.02   \n",
       "3                 255                    1.00                    0.00   \n",
       "4                 255                    1.00                    0.00   \n",
       "\n",
       "   dst_host_serror_rate  class  \n",
       "0                   0.0      1  \n",
       "1                   1.0      0  \n",
       "2                   1.0      0  \n",
       "3                   0.0      1  \n",
       "4                   0.0      1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(r\"..\\API\\data\\processed\\train_data.csv\")\n",
    "df_test=pd.read_csv(r\"..\\API\\data\\processed\\test_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "280fab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20153, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c3b3605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test= train_test_split(df.drop([\"class\"],axis=1),df['class'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd73a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training into actual training and validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b4cbc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.5279522369543305 \n",
      " Testing accuracy: 0.9263210121557927 \n",
      " Precision: 0.9287755946087501 \n",
      " Recall: 0.9263210121557927 \n",
      " F1 Score: 0.9260041260033283 \n",
      " \n",
      " Confusion Matrix: \n",
      " [[1655  230]\n",
      " [  67 2079]] \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      1885\n",
      "           1       0.90      0.97      0.93      2146\n",
      "\n",
      "    accuracy                           0.93      4031\n",
      "   macro avg       0.93      0.92      0.93      4031\n",
      "weighted avg       0.93      0.93      0.93      4031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "train_acc=accuracy_score(y_train, classifier.predict(np.array(x_train)))\n",
    "test_acc=accuracy_score(y_test, y_pred)\n",
    "precision=precision_score(y_test, y_pred, average=\"weighted\")\n",
    "recall=recall_score(y_test, y_pred, average=\"weighted\")\n",
    "f1_score=f1_score(y_test, y_pred, average=\"weighted\")\n",
    "conf_matrix=confusion_matrix(y_test, y_pred)\n",
    "print(f'Training accuracy: {train_acc} \\n Testing accuracy: {test_acc} \\n Precision: {precision} \\n Recall: {recall} \\n F1 Score: {f1_score} \\n \\n Confusion Matrix: \\n {conf_matrix} \\n \\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69b535c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss: 0.3732, Validation Loss: 0.4642\n",
      "Epoch 50, Training Loss: 0.1803, Validation Loss: 0.1867\n",
      "Epoch 100, Training Loss: 0.1339, Validation Loss: 0.1324\n",
      "Epoch 150, Training Loss: 0.1179, Validation Loss: 0.1194\n",
      "Epoch 200, Training Loss: 0.1058, Validation Loss: 0.1219\n",
      "Epoch 250, Training Loss: 0.0972, Validation Loss: 0.1144\n",
      "Epoch 300, Training Loss: 0.0906, Validation Loss: 0.1104\n",
      "Epoch 350, Training Loss: 0.0860, Validation Loss: 0.1039\n",
      "Epoch 400, Training Loss: 0.0830, Validation Loss: 0.0890\n",
      "Epoch 450, Training Loss: 0.0809, Validation Loss: 0.0784\n",
      "Param: (500, 0.1) \n",
      "Score: 0.9104440585462664 \n",
      "\n",
      "Epoch 0, Training Loss: 0.2783, Validation Loss: 0.4691\n",
      "Epoch 50, Training Loss: 0.0938, Validation Loss: 0.0812\n",
      "Epoch 100, Training Loss: 0.0783, Validation Loss: 0.0772\n",
      "Epoch 150, Training Loss: 0.0716, Validation Loss: 0.0781\n",
      "Epoch 200, Training Loss: 0.0673, Validation Loss: 0.0778\n",
      "Epoch 250, Training Loss: 0.0645, Validation Loss: 0.0775\n",
      "Epoch 300, Training Loss: 0.0623, Validation Loss: 0.0710\n",
      "Epoch 350, Training Loss: 0.0609, Validation Loss: 0.0704\n",
      "Epoch 400, Training Loss: 0.0596, Validation Loss: 0.0664\n",
      "Epoch 450, Training Loss: 0.0587, Validation Loss: 0.0660\n",
      "Param: (500, 0.2) \n",
      "Score: 0.9307864053584718 \n",
      "\n",
      "Epoch 0, Training Loss: 0.3450, Validation Loss: 0.5188\n",
      "Epoch 50, Training Loss: 0.1121, Validation Loss: 0.1650\n",
      "Epoch 100, Training Loss: 0.0848, Validation Loss: 0.1033\n",
      "Epoch 150, Training Loss: 0.0725, Validation Loss: 0.0620\n",
      "Epoch 200, Training Loss: 0.0651, Validation Loss: 0.0574\n",
      "Epoch 250, Training Loss: 0.0614, Validation Loss: 0.0564\n",
      "Epoch 300, Training Loss: 0.0584, Validation Loss: 0.0549\n",
      "Epoch 350, Training Loss: 0.0548, Validation Loss: 0.0543\n",
      "Epoch 400, Training Loss: 0.0529, Validation Loss: 0.0536\n",
      "Epoch 450, Training Loss: 0.0515, Validation Loss: 0.0536\n",
      "Param: (500, 0.5) \n",
      "Score: 0.9481518233688911 \n",
      "\n",
      "Epoch 0, Training Loss: 0.2439, Validation Loss: 0.3764\n",
      "Epoch 50, Training Loss: 0.1623, Validation Loss: 0.2189\n",
      "Epoch 100, Training Loss: 0.1195, Validation Loss: 0.1181\n",
      "Epoch 150, Training Loss: 0.0981, Validation Loss: 0.1045\n",
      "Epoch 200, Training Loss: 0.0872, Validation Loss: 0.0744\n",
      "Epoch 250, Training Loss: 0.0793, Validation Loss: 0.0639\n",
      "Epoch 300, Training Loss: 0.0730, Validation Loss: 0.0580\n",
      "Epoch 350, Training Loss: 0.0689, Validation Loss: 0.0564\n",
      "Epoch 400, Training Loss: 0.0656, Validation Loss: 0.0561\n",
      "Epoch 450, Training Loss: 0.0631, Validation Loss: 0.0552\n",
      "Epoch 500, Training Loss: 0.0612, Validation Loss: 0.0540\n",
      "Epoch 550, Training Loss: 0.0597, Validation Loss: 0.0540\n",
      "Epoch 600, Training Loss: 0.0583, Validation Loss: 0.0543\n",
      "Epoch 650, Training Loss: 0.0574, Validation Loss: 0.0543\n",
      "Epoch 700, Training Loss: 0.0567, Validation Loss: 0.0540\n",
      "Epoch 750, Training Loss: 0.0562, Validation Loss: 0.0536\n",
      "Epoch 800, Training Loss: 0.0557, Validation Loss: 0.0536\n",
      "Epoch 850, Training Loss: 0.0552, Validation Loss: 0.0540\n",
      "Epoch 900, Training Loss: 0.0547, Validation Loss: 0.0536\n",
      "Epoch 950, Training Loss: 0.0543, Validation Loss: 0.0533\n",
      "Param: (1000, 0.1) \n",
      "Score: 0.9424460431654677 \n",
      "\n",
      "Epoch 0, Training Loss: 0.5393, Validation Loss: 0.5820\n",
      "Epoch 50, Training Loss: 0.2067, Validation Loss: 0.2595\n",
      "Epoch 100, Training Loss: 0.1049, Validation Loss: 0.1181\n",
      "Epoch 150, Training Loss: 0.0850, Validation Loss: 0.1033\n",
      "Epoch 200, Training Loss: 0.0753, Validation Loss: 0.0837\n",
      "Epoch 250, Training Loss: 0.0703, Validation Loss: 0.0822\n",
      "Epoch 300, Training Loss: 0.0667, Validation Loss: 0.0791\n",
      "Epoch 350, Training Loss: 0.0642, Validation Loss: 0.0747\n",
      "Epoch 400, Training Loss: 0.0622, Validation Loss: 0.0738\n",
      "Epoch 450, Training Loss: 0.0606, Validation Loss: 0.0729\n",
      "Epoch 500, Training Loss: 0.0594, Validation Loss: 0.0726\n",
      "Epoch 550, Training Loss: 0.0585, Validation Loss: 0.0713\n",
      "Epoch 600, Training Loss: 0.0576, Validation Loss: 0.0713\n",
      "Epoch 650, Training Loss: 0.0569, Validation Loss: 0.0710\n",
      "Epoch 700, Training Loss: 0.0563, Validation Loss: 0.0710\n",
      "Epoch 750, Training Loss: 0.0558, Validation Loss: 0.0704\n",
      "Epoch 800, Training Loss: 0.0553, Validation Loss: 0.0704\n",
      "Epoch 850, Training Loss: 0.0547, Validation Loss: 0.0691\n",
      "Epoch 900, Training Loss: 0.0543, Validation Loss: 0.0685\n",
      "Epoch 950, Training Loss: 0.0540, Validation Loss: 0.0685\n",
      "Param: (1000, 0.2) \n",
      "Score: 0.9278094765566857 \n",
      "\n",
      "Epoch 0, Training Loss: 0.4218, Validation Loss: 0.4642\n",
      "Epoch 50, Training Loss: 0.1092, Validation Loss: 0.0971\n",
      "Epoch 100, Training Loss: 0.0794, Validation Loss: 0.0859\n",
      "Epoch 150, Training Loss: 0.0699, Validation Loss: 0.0847\n",
      "Epoch 200, Training Loss: 0.0650, Validation Loss: 0.0847\n",
      "Epoch 250, Training Loss: 0.0621, Validation Loss: 0.0797\n",
      "Epoch 300, Training Loss: 0.0598, Validation Loss: 0.0757\n",
      "Epoch 350, Training Loss: 0.0582, Validation Loss: 0.0707\n",
      "Epoch 400, Training Loss: 0.0557, Validation Loss: 0.0660\n",
      "Epoch 450, Training Loss: 0.0543, Validation Loss: 0.0577\n",
      "Epoch 500, Training Loss: 0.0529, Validation Loss: 0.0546\n",
      "Epoch 550, Training Loss: 0.0513, Validation Loss: 0.0543\n",
      "Epoch 600, Training Loss: 0.0504, Validation Loss: 0.0540\n",
      "Epoch 650, Training Loss: 0.0496, Validation Loss: 0.0533\n",
      "Epoch 700, Training Loss: 0.0488, Validation Loss: 0.0533\n",
      "Epoch 750, Training Loss: 0.0481, Validation Loss: 0.0530\n",
      "Epoch 800, Training Loss: 0.0475, Validation Loss: 0.0530\n",
      "Epoch 850, Training Loss: 0.0469, Validation Loss: 0.0546\n",
      "Epoch 900, Training Loss: 0.0464, Validation Loss: 0.0546\n",
      "Epoch 950, Training Loss: 0.0458, Validation Loss: 0.0549\n",
      "Param: (1000, 0.5) \n",
      "Score: 0.9451748945671049 \n",
      "\n",
      "Epoch 0, Training Loss: 0.3982, Validation Loss: 0.7169\n",
      "Epoch 50, Training Loss: 0.2290, Validation Loss: 0.4440\n",
      "Epoch 100, Training Loss: 0.1861, Validation Loss: 0.2307\n",
      "Epoch 150, Training Loss: 0.1562, Validation Loss: 0.2009\n",
      "Epoch 200, Training Loss: 0.1356, Validation Loss: 0.1392\n",
      "Epoch 250, Training Loss: 0.1194, Validation Loss: 0.1315\n",
      "Epoch 300, Training Loss: 0.1124, Validation Loss: 0.1340\n",
      "Epoch 350, Training Loss: 0.0994, Validation Loss: 0.1153\n",
      "Epoch 400, Training Loss: 0.0911, Validation Loss: 0.1064\n",
      "Epoch 450, Training Loss: 0.0844, Validation Loss: 0.0992\n",
      "Epoch 500, Training Loss: 0.0782, Validation Loss: 0.0946\n",
      "Epoch 550, Training Loss: 0.0730, Validation Loss: 0.0825\n",
      "Epoch 600, Training Loss: 0.0693, Validation Loss: 0.0775\n",
      "Epoch 650, Training Loss: 0.0670, Validation Loss: 0.0769\n",
      "Epoch 700, Training Loss: 0.0654, Validation Loss: 0.0769\n",
      "Epoch 750, Training Loss: 0.0648, Validation Loss: 0.0766\n",
      "Epoch 800, Training Loss: 0.0634, Validation Loss: 0.0772\n",
      "Epoch 850, Training Loss: 0.0622, Validation Loss: 0.0769\n",
      "Epoch 900, Training Loss: 0.0610, Validation Loss: 0.0753\n",
      "Epoch 950, Training Loss: 0.0602, Validation Loss: 0.0750\n",
      "Epoch 1000, Training Loss: 0.0599, Validation Loss: 0.0747\n",
      "Epoch 1050, Training Loss: 0.0591, Validation Loss: 0.0741\n",
      "Epoch 1100, Training Loss: 0.0584, Validation Loss: 0.0729\n",
      "Epoch 1150, Training Loss: 0.0578, Validation Loss: 0.0685\n",
      "Epoch 1200, Training Loss: 0.0569, Validation Loss: 0.0660\n",
      "Epoch 1250, Training Loss: 0.0561, Validation Loss: 0.0654\n",
      "Epoch 1300, Training Loss: 0.0554, Validation Loss: 0.0651\n",
      "Epoch 1350, Training Loss: 0.0549, Validation Loss: 0.0651\n",
      "Epoch 1400, Training Loss: 0.0540, Validation Loss: 0.0648\n",
      "Epoch 1450, Training Loss: 0.0535, Validation Loss: 0.0648\n",
      "Param: (1500, 0.1) \n",
      "Score: 0.9297940957578764 \n",
      "\n",
      "Epoch 0, Training Loss: 0.1981, Validation Loss: 0.2366\n",
      "Epoch 50, Training Loss: 0.1238, Validation Loss: 0.1011\n",
      "Epoch 100, Training Loss: 0.1071, Validation Loss: 0.0933\n",
      "Epoch 150, Training Loss: 0.0950, Validation Loss: 0.0884\n",
      "Epoch 200, Training Loss: 0.0869, Validation Loss: 0.0840\n",
      "Epoch 250, Training Loss: 0.0808, Validation Loss: 0.0816\n",
      "Epoch 300, Training Loss: 0.0764, Validation Loss: 0.0784\n",
      "Epoch 350, Training Loss: 0.0733, Validation Loss: 0.0772\n",
      "Epoch 400, Training Loss: 0.0707, Validation Loss: 0.0750\n",
      "Epoch 450, Training Loss: 0.0686, Validation Loss: 0.0732\n",
      "Epoch 500, Training Loss: 0.0668, Validation Loss: 0.0732\n",
      "Epoch 550, Training Loss: 0.0653, Validation Loss: 0.0822\n",
      "Epoch 600, Training Loss: 0.0641, Validation Loss: 0.0819\n",
      "Epoch 650, Training Loss: 0.0630, Validation Loss: 0.0816\n",
      "Epoch 700, Training Loss: 0.0618, Validation Loss: 0.0797\n",
      "Epoch 750, Training Loss: 0.0609, Validation Loss: 0.0788\n",
      "Epoch 800, Training Loss: 0.0601, Validation Loss: 0.0781\n",
      "Epoch 850, Training Loss: 0.0594, Validation Loss: 0.0778\n",
      "Epoch 900, Training Loss: 0.0587, Validation Loss: 0.0766\n",
      "Epoch 950, Training Loss: 0.0581, Validation Loss: 0.0766\n",
      "Epoch 1000, Training Loss: 0.0576, Validation Loss: 0.0763\n",
      "Epoch 1050, Training Loss: 0.0570, Validation Loss: 0.0750\n",
      "Epoch 1100, Training Loss: 0.0553, Validation Loss: 0.0750\n",
      "Epoch 1150, Training Loss: 0.0548, Validation Loss: 0.0760\n",
      "Epoch 1200, Training Loss: 0.0544, Validation Loss: 0.0757\n",
      "Epoch 1250, Training Loss: 0.0540, Validation Loss: 0.0760\n",
      "Epoch 1300, Training Loss: 0.0536, Validation Loss: 0.0760\n",
      "Epoch 1350, Training Loss: 0.0532, Validation Loss: 0.0757\n",
      "Epoch 1400, Training Loss: 0.0529, Validation Loss: 0.0757\n",
      "Epoch 1450, Training Loss: 0.0521, Validation Loss: 0.0757\n",
      "Param: (1500, 0.2) \n",
      "Score: 0.927313321756388 \n",
      "\n",
      "Epoch 0, Training Loss: 0.4042, Validation Loss: 0.4642\n",
      "Epoch 50, Training Loss: 0.0840, Validation Loss: 0.1122\n",
      "Epoch 100, Training Loss: 0.0674, Validation Loss: 0.0713\n",
      "Epoch 150, Training Loss: 0.0606, Validation Loss: 0.0760\n",
      "Epoch 200, Training Loss: 0.0566, Validation Loss: 0.0753\n",
      "Epoch 250, Training Loss: 0.0547, Validation Loss: 0.0747\n",
      "Epoch 300, Training Loss: 0.0531, Validation Loss: 0.0744\n",
      "Epoch 350, Training Loss: 0.0519, Validation Loss: 0.0735\n",
      "Epoch 400, Training Loss: 0.0509, Validation Loss: 0.0735\n",
      "Epoch 450, Training Loss: 0.0487, Validation Loss: 0.0719\n",
      "Epoch 500, Training Loss: 0.0478, Validation Loss: 0.0716\n",
      "Epoch 550, Training Loss: 0.0470, Validation Loss: 0.0710\n",
      "Epoch 600, Training Loss: 0.0462, Validation Loss: 0.0701\n",
      "Epoch 650, Training Loss: 0.0453, Validation Loss: 0.0657\n",
      "Epoch 700, Training Loss: 0.0444, Validation Loss: 0.0580\n",
      "Epoch 750, Training Loss: 0.0433, Validation Loss: 0.0574\n",
      "Epoch 800, Training Loss: 0.0426, Validation Loss: 0.0567\n",
      "Epoch 850, Training Loss: 0.0419, Validation Loss: 0.0567\n",
      "Epoch 900, Training Loss: 0.0413, Validation Loss: 0.0567\n",
      "Epoch 950, Training Loss: 0.0407, Validation Loss: 0.0555\n",
      "Epoch 1000, Training Loss: 0.0400, Validation Loss: 0.0533\n",
      "Epoch 1050, Training Loss: 0.0395, Validation Loss: 0.0471\n",
      "Epoch 1100, Training Loss: 0.0390, Validation Loss: 0.0462\n",
      "Epoch 1150, Training Loss: 0.0383, Validation Loss: 0.0447\n",
      "Epoch 1200, Training Loss: 0.0377, Validation Loss: 0.0462\n",
      "Epoch 1250, Training Loss: 0.0369, Validation Loss: 0.0456\n",
      "Epoch 1300, Training Loss: 0.0363, Validation Loss: 0.0450\n",
      "Epoch 1350, Training Loss: 0.0358, Validation Loss: 0.0378\n",
      "Epoch 1400, Training Loss: 0.0352, Validation Loss: 0.0381\n",
      "Epoch 1450, Training Loss: 0.0349, Validation Loss: 0.0381\n",
      "Param: (1500, 0.5) \n",
      "Score: 0.9665095509799058 \n",
      "\n",
      "Best score: 0.9665095509799058 \n",
      " Best param: {'epochs': 1500, 'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "param_grid = {\n",
    "    'epochs': [500, 1000, 1500],\n",
    "    'learning_rate': [0.1, 0.2, 0.5],\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best_param = None\n",
    "\n",
    "for epoch in param_grid['epochs']:\n",
    "    for lr in param_grid['learning_rate']:\n",
    "        classifier=NeuralNetwork([10, 32, 16, 1], activation='sigmoid')\n",
    "        classifier.train(\n",
    "            np.array(x_train), np.array(y_train),\n",
    "            epochs=epoch,\n",
    "            learning_rate=lr,\n",
    "            x_val=np.array(x_val),\n",
    "            y_val=np.array(y_val)\n",
    "        )\n",
    "        y_pred=classifier.predict(np.array(x_test))\n",
    "        test_acc=accuracy_score(y_test, y_pred)\n",
    "        print(f'Param: {epoch,lr} \\nScore: {test_acc} \\n')\n",
    "        if test_acc > best_score:\n",
    "            best_score = test_acc\n",
    "            best_param = {'epochs': epoch, 'learning_rate': lr}\n",
    "\n",
    "print(f'Best score: {best_score} \\n Best param: {best_param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fabca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss: 0.5155, Validation Loss: 0.5358\n",
      "Epoch 50, Training Loss: 0.1352, Validation Loss: 0.1374\n",
      "Epoch 100, Training Loss: 0.0978, Validation Loss: 0.0732\n",
      "Epoch 150, Training Loss: 0.0853, Validation Loss: 0.0735\n",
      "Epoch 200, Training Loss: 0.0777, Validation Loss: 0.0707\n",
      "Epoch 250, Training Loss: 0.0733, Validation Loss: 0.0704\n",
      "Epoch 300, Training Loss: 0.0700, Validation Loss: 0.0704\n",
      "Epoch 350, Training Loss: 0.0671, Validation Loss: 0.0695\n",
      "Epoch 400, Training Loss: 0.0646, Validation Loss: 0.0685\n",
      "Epoch 450, Training Loss: 0.0623, Validation Loss: 0.0651\n",
      "Epoch 500, Training Loss: 0.0595, Validation Loss: 0.0639\n",
      "Epoch 550, Training Loss: 0.0576, Validation Loss: 0.0633\n",
      "Epoch 600, Training Loss: 0.0545, Validation Loss: 0.0629\n",
      "Epoch 650, Training Loss: 0.0534, Validation Loss: 0.0651\n",
      "Epoch 700, Training Loss: 0.0523, Validation Loss: 0.0642\n",
      "Epoch 750, Training Loss: 0.0496, Validation Loss: 0.0626\n",
      "Epoch 800, Training Loss: 0.0487, Validation Loss: 0.0558\n",
      "Epoch 850, Training Loss: 0.0479, Validation Loss: 0.0540\n",
      "Epoch 900, Training Loss: 0.0470, Validation Loss: 0.0540\n",
      "Epoch 950, Training Loss: 0.0473, Validation Loss: 0.0499\n",
      "Epoch 1000, Training Loss: 0.0462, Validation Loss: 0.0502\n",
      "Epoch 1050, Training Loss: 0.0455, Validation Loss: 0.0505\n",
      "Epoch 1100, Training Loss: 0.0448, Validation Loss: 0.0509\n",
      "Epoch 1150, Training Loss: 0.0442, Validation Loss: 0.0502\n",
      "Epoch 1200, Training Loss: 0.0436, Validation Loss: 0.0509\n",
      "Epoch 1250, Training Loss: 0.0430, Validation Loss: 0.0505\n",
      "Epoch 1300, Training Loss: 0.0425, Validation Loss: 0.0509\n",
      "Epoch 1350, Training Loss: 0.0418, Validation Loss: 0.0502\n",
      "Epoch 1400, Training Loss: 0.0412, Validation Loss: 0.0468\n",
      "Epoch 1450, Training Loss: 0.0407, Validation Loss: 0.0459\n",
      "Param: (1500, 0.5) \n",
      "Score: 0.9580749193748449 \n",
      "\n",
      "Epoch 0, Training Loss: 0.4692, Validation Loss: 0.5358\n",
      "Epoch 50, Training Loss: 0.0856, Validation Loss: 0.0884\n",
      "Epoch 100, Training Loss: 0.0721, Validation Loss: 0.0819\n",
      "Epoch 150, Training Loss: 0.0648, Validation Loss: 0.0719\n",
      "Epoch 200, Training Loss: 0.0608, Validation Loss: 0.0719\n",
      "Epoch 250, Training Loss: 0.0567, Validation Loss: 0.0688\n",
      "Epoch 300, Training Loss: 0.0543, Validation Loss: 0.0688\n",
      "Epoch 350, Training Loss: 0.0521, Validation Loss: 0.0685\n",
      "Epoch 400, Training Loss: 0.0503, Validation Loss: 0.0676\n",
      "Epoch 450, Training Loss: 0.0489, Validation Loss: 0.0654\n",
      "Epoch 500, Training Loss: 0.0476, Validation Loss: 0.0605\n",
      "Epoch 550, Training Loss: 0.0465, Validation Loss: 0.0533\n",
      "Epoch 600, Training Loss: 0.0455, Validation Loss: 0.0543\n",
      "Epoch 650, Training Loss: 0.0446, Validation Loss: 0.0543\n",
      "Epoch 700, Training Loss: 0.0438, Validation Loss: 0.0533\n",
      "Epoch 750, Training Loss: 0.0432, Validation Loss: 0.0527\n",
      "Epoch 800, Training Loss: 0.0427, Validation Loss: 0.0521\n",
      "Epoch 850, Training Loss: 0.0422, Validation Loss: 0.0521\n",
      "Epoch 900, Training Loss: 0.0418, Validation Loss: 0.0499\n",
      "Epoch 950, Training Loss: 0.0413, Validation Loss: 0.0496\n",
      "Epoch 1000, Training Loss: 0.0410, Validation Loss: 0.0493\n",
      "Epoch 1050, Training Loss: 0.0407, Validation Loss: 0.0496\n",
      "Epoch 1100, Training Loss: 0.0403, Validation Loss: 0.0490\n",
      "Epoch 1150, Training Loss: 0.0401, Validation Loss: 0.0484\n",
      "Epoch 1200, Training Loss: 0.0398, Validation Loss: 0.0471\n",
      "Epoch 1250, Training Loss: 0.0394, Validation Loss: 0.0443\n",
      "Epoch 1300, Training Loss: 0.0392, Validation Loss: 0.0443\n",
      "Epoch 1350, Training Loss: 0.0391, Validation Loss: 0.0443\n",
      "Epoch 1400, Training Loss: 0.0389, Validation Loss: 0.0447\n",
      "Epoch 1450, Training Loss: 0.0387, Validation Loss: 0.0440\n",
      "Param: (1500, 0.8) \n",
      "Score: 0.9533614487720169 \n",
      "\n",
      "Epoch 0, Training Loss: 0.2703, Validation Loss: 0.6121\n",
      "Epoch 50, Training Loss: 0.0654, Validation Loss: 0.0614\n",
      "Epoch 100, Training Loss: 0.0572, Validation Loss: 0.0614\n",
      "Epoch 150, Training Loss: 0.0535, Validation Loss: 0.0623\n",
      "Epoch 200, Training Loss: 0.0512, Validation Loss: 0.0620\n",
      "Epoch 250, Training Loss: 0.0498, Validation Loss: 0.0608\n",
      "Epoch 300, Training Loss: 0.0481, Validation Loss: 0.0589\n",
      "Epoch 350, Training Loss: 0.0475, Validation Loss: 0.0595\n",
      "Epoch 400, Training Loss: 0.0472, Validation Loss: 0.0549\n",
      "Epoch 450, Training Loss: 0.0463, Validation Loss: 0.0567\n",
      "Epoch 500, Training Loss: 0.0455, Validation Loss: 0.0555\n",
      "Epoch 550, Training Loss: 0.0451, Validation Loss: 0.0536\n",
      "Epoch 600, Training Loss: 0.0445, Validation Loss: 0.0540\n",
      "Epoch 650, Training Loss: 0.0442, Validation Loss: 0.0536\n",
      "Epoch 700, Training Loss: 0.0435, Validation Loss: 0.0505\n",
      "Epoch 750, Training Loss: 0.0431, Validation Loss: 0.0505\n",
      "Epoch 800, Training Loss: 0.0429, Validation Loss: 0.0521\n",
      "Epoch 850, Training Loss: 0.0425, Validation Loss: 0.0521\n",
      "Epoch 900, Training Loss: 0.0421, Validation Loss: 0.0521\n",
      "Epoch 950, Training Loss: 0.0431, Validation Loss: 0.0546\n",
      "Epoch 1000, Training Loss: 0.0415, Validation Loss: 0.0518\n",
      "Epoch 1050, Training Loss: 0.0419, Validation Loss: 0.0540\n",
      "Epoch 1100, Training Loss: 0.0407, Validation Loss: 0.0512\n",
      "Epoch 1150, Training Loss: 0.0404, Validation Loss: 0.0512\n",
      "Epoch 1200, Training Loss: 0.0403, Validation Loss: 0.0521\n",
      "Epoch 1250, Training Loss: 0.0452, Validation Loss: 0.0564\n",
      "Epoch 1300, Training Loss: 0.0439, Validation Loss: 0.0536\n",
      "Epoch 1350, Training Loss: 0.0428, Validation Loss: 0.0527\n",
      "Epoch 1400, Training Loss: 0.0418, Validation Loss: 0.0527\n",
      "Epoch 1450, Training Loss: 0.0410, Validation Loss: 0.0524\n",
      "Epoch 1500, Training Loss: 0.0404, Validation Loss: 0.0524\n",
      "Epoch 1550, Training Loss: 0.0398, Validation Loss: 0.0524\n",
      "Epoch 1600, Training Loss: 0.0394, Validation Loss: 0.0515\n",
      "Epoch 1650, Training Loss: 0.0390, Validation Loss: 0.0512\n",
      "Epoch 1700, Training Loss: 0.0386, Validation Loss: 0.0512\n",
      "Epoch 1750, Training Loss: 0.0382, Validation Loss: 0.0502\n",
      "Epoch 1800, Training Loss: 0.0379, Validation Loss: 0.0502\n",
      "Epoch 1850, Training Loss: 0.0377, Validation Loss: 0.0502\n",
      "Epoch 1900, Training Loss: 0.0374, Validation Loss: 0.0499\n",
      "Epoch 1950, Training Loss: 0.0371, Validation Loss: 0.0499\n",
      "Param: (2000, 0.5) \n",
      "Score: 0.9506325973703795 \n",
      "\n",
      "Epoch 0, Training Loss: 0.4847, Validation Loss: 0.5358\n",
      "Epoch 50, Training Loss: 0.0831, Validation Loss: 0.0809\n",
      "Epoch 100, Training Loss: 0.0643, Validation Loss: 0.0577\n",
      "Epoch 150, Training Loss: 0.0571, Validation Loss: 0.0512\n",
      "Epoch 200, Training Loss: 0.0533, Validation Loss: 0.0505\n",
      "Epoch 250, Training Loss: 0.0505, Validation Loss: 0.0505\n",
      "Epoch 300, Training Loss: 0.0484, Validation Loss: 0.0524\n",
      "Epoch 350, Training Loss: 0.0470, Validation Loss: 0.0527\n",
      "Epoch 400, Training Loss: 0.0459, Validation Loss: 0.0524\n",
      "Epoch 450, Training Loss: 0.0450, Validation Loss: 0.0524\n",
      "Epoch 500, Training Loss: 0.0443, Validation Loss: 0.0524\n",
      "Epoch 550, Training Loss: 0.0467, Validation Loss: 0.0515\n",
      "Epoch 600, Training Loss: 0.0459, Validation Loss: 0.0512\n",
      "Epoch 650, Training Loss: 0.0454, Validation Loss: 0.0512\n",
      "Epoch 700, Training Loss: 0.0450, Validation Loss: 0.0512\n",
      "Epoch 750, Training Loss: 0.0447, Validation Loss: 0.0509\n",
      "Epoch 800, Training Loss: 0.0443, Validation Loss: 0.0505\n",
      "Epoch 850, Training Loss: 0.0440, Validation Loss: 0.0505\n",
      "Epoch 900, Training Loss: 0.0438, Validation Loss: 0.0505\n",
      "Epoch 950, Training Loss: 0.0434, Validation Loss: 0.0505\n",
      "Epoch 1000, Training Loss: 0.0432, Validation Loss: 0.0505\n",
      "Epoch 1050, Training Loss: 0.0429, Validation Loss: 0.0505\n",
      "Epoch 1100, Training Loss: 0.0427, Validation Loss: 0.0505\n",
      "Epoch 1150, Training Loss: 0.0425, Validation Loss: 0.0505\n",
      "Epoch 1200, Training Loss: 0.0422, Validation Loss: 0.0496\n",
      "Epoch 1250, Training Loss: 0.0420, Validation Loss: 0.0493\n",
      "Epoch 1300, Training Loss: 0.0418, Validation Loss: 0.0490\n",
      "Epoch 1350, Training Loss: 0.0415, Validation Loss: 0.0487\n",
      "Epoch 1400, Training Loss: 0.0413, Validation Loss: 0.0481\n",
      "Epoch 1450, Training Loss: 0.0411, Validation Loss: 0.0450\n",
      "Epoch 1500, Training Loss: 0.0409, Validation Loss: 0.0453\n",
      "Epoch 1550, Training Loss: 0.0407, Validation Loss: 0.0453\n",
      "Epoch 1600, Training Loss: 0.0405, Validation Loss: 0.0453\n",
      "Epoch 1650, Training Loss: 0.0403, Validation Loss: 0.0453\n",
      "Epoch 1700, Training Loss: 0.0401, Validation Loss: 0.0453\n",
      "Epoch 1750, Training Loss: 0.0398, Validation Loss: 0.0450\n",
      "Epoch 1800, Training Loss: 0.0395, Validation Loss: 0.0450\n",
      "Epoch 1850, Training Loss: 0.0392, Validation Loss: 0.0447\n",
      "Epoch 1900, Training Loss: 0.0390, Validation Loss: 0.0456\n",
      "Epoch 1950, Training Loss: 0.0389, Validation Loss: 0.0459\n",
      "Param: (2000, 0.8) \n",
      "Score: 0.9523691391714215 \n",
      "\n",
      "Best score: 0.9580749193748449 \n",
      " Best param: {'epochs': 1500, 'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'epochs': [1500,2000],\n",
    "    'learning_rate': [0.5,0.8],\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best_param = None\n",
    "\n",
    "for epoch in param_grid['epochs']:\n",
    "    for lr in param_grid['learning_rate']:\n",
    "        classifier=NeuralNetwork([10, 32, 16, 1], activation='sigmoid')\n",
    "        classifier.train(\n",
    "            np.array(x_train), np.array(y_train),\n",
    "            epochs=epoch,\n",
    "            learning_rate=lr,\n",
    "            x_val=np.array(x_val),\n",
    "            y_val=np.array(y_val)\n",
    "        )\n",
    "        y_pred=classifier.predict(np.array(x_test))\n",
    "        test_acc=accuracy_score(y_test, y_pred)\n",
    "        print(f'Param: {epoch,lr} \\nScore: {test_acc} \\n')\n",
    "        if test_acc > best_score:\n",
    "            best_score = test_acc\n",
    "            best_param = {'epochs': epoch, 'learning_rate': lr}\n",
    "\n",
    "print(f'Best score: {best_score} \\n Best param: {best_param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "763c888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save best hyperparameters\n",
    "with open(r\"..\\API\\model\\Hyperparams\\ANN_hparam.json\", \"w\") as f:\n",
    "    json.dump(best_param, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15f035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
